ğ—¦ğ—Ÿğ—œ: ğ—ªğ—µğ—®ğ˜â€™ğ˜€ ğ—¿ğ—²ğ—®ğ—¹ğ—¹ğ˜† ğ—µğ—®ğ—½ğ—½ğ—²ğ—»ğ—¶ğ—»ğ—´

This is just a number that tells you how your service is doing.
 Example:
"99.9% ğ˜°ğ˜§ ğ˜°ğ˜¶ğ˜³ ğ˜¶ğ˜´ğ˜¦ğ˜³ğ˜´ ğ˜¨ğ˜°ğ˜µ ğ˜¢ ğ˜³ğ˜¦ğ˜´ğ˜±ğ˜°ğ˜¯ğ˜´ğ˜¦ ğ˜¸ğ˜ªğ˜µğ˜©ğ˜°ğ˜¶ğ˜µ ğ˜¦ğ˜³ğ˜³ğ˜°ğ˜³ğ˜´."

It measures Availabililty, Latency , error rate, throughput.
Eg. In the last 30 days 99.9% of HTTP requests responded with status code 200 within 500ms.
This is SLI for availability and latency.

How to measure SLI:-
1) Availability:-
prometheus + Grafana
we write promQL queries to measure success vs total requests.
rate(http_request_total){status=~"2.."}[5m])
/
rate(http_request_total[5m])

This gives % of successful HTTP responses in the last 5 minutes.

2) Latency:-
  Latency measures the time taken for a system to respond to request. in practice we track 95th or 99th percentile. meaning 95% of requests should complete within a defined threshold like 500ms or 1 second

  Tools like prometheus use http_request_duration_second_bucket to record response duration and histogram quantile(0.95..) is used to calculate p95 latency.

3) Error rate:-
  Error rate tracks the % of requests that fail, typically HTTP 500 status codes.it helps us catch issue early. even before users report them.

  rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m])

To calculate the ratio of failed request to total.

4) Throughtput: 
     throughput measures how many requests per second the system is handling. this help us understand system load and scalability.
      we use rate(http_request_total[1m]) in prometheus to see the per-second request rate.if it spikes it may indicate high load or potential DDos attack.

ğ—¦ğ—Ÿğ—¢: ğ—ªğ—µğ—®ğ˜ ğ˜†ğ—¼ğ˜‚ ğ—®ğ—¶ğ—º ğ—³ğ—¼ğ—¿

This is the target you want to hit.
 You set it to keep your service reliable.
 Example:
"ğ˜ğ˜¦ ğ˜¸ğ˜¢ğ˜¯ğ˜µ ğ˜¢ğ˜µ ğ˜­ğ˜¦ğ˜¢ğ˜´ğ˜µ 99.9% ğ˜´ğ˜¶ğ˜¤ğ˜¤ğ˜¦ğ˜´ğ˜´ ğ˜³ğ˜¢ğ˜µğ˜¦ ğ˜¦ğ˜·ğ˜¦ğ˜³ğ˜º ğ˜®ğ˜°ğ˜¯ğ˜µğ˜©."

ğ—¦ğ—Ÿğ—”: ğ—ªğ—µğ—®ğ˜ ğ˜†ğ—¼ğ˜‚ ğ—½ğ—¿ğ—¼ğ—ºğ—¶ğ˜€ğ—² ğ—¼ğ˜ğ—µğ—²ğ—¿ğ˜€

This is a formal agreement with your customers.
 If you donâ€™t meet it, there might be a penalty.
 Example:
"ğ˜ğ˜§ ğ˜¶ğ˜±ğ˜µğ˜ªğ˜®ğ˜¦ ğ˜¥ğ˜³ğ˜°ğ˜±ğ˜´ ğ˜£ğ˜¦ğ˜­ğ˜°ğ˜¸ 99.95%, ğ˜¸ğ˜¦â€™ğ˜­ğ˜­ ğ˜¨ğ˜ªğ˜·ğ˜¦ ğ˜¢ ğ˜±ğ˜¢ğ˜³ğ˜µğ˜ªğ˜¢ğ˜­ ğ˜³ğ˜¦ğ˜§ğ˜¶ğ˜¯ğ˜¥."

ğ—ªğ—µğ˜† ğ˜€ğ—µğ—¼ğ˜‚ğ—¹ğ—± ğ˜†ğ—¼ğ˜‚ ğ—°ğ—®ğ—¿ğ—²?
These are not just buzzwords. They help teams build better, more reliable systems and avoid late-night fire issues.

------------------------------------------------------------------------------------------------------------------------------------

MTTR  -Mean time to resolve

MTTR - Mean time to resolve/repair -- The average time it takes to resolve an outage and resolve service to end-users.
   MTTR = Total Downtime
          ---------------
          No of failure


MTBF - Mean time between failure  -- The average time from one incident to the next.
   MTBF = Mean time between failure
          --------------
          No of failure


MTTA- Mean time to acknowledge
         The average time it takes for a new open incident to be acknowledged.

          time to acknowledge 
          --------------------
          # of incidents

Error  udget and error rate 

Error Budget is == 100% Reliability - 0.1% Downtime.

![alt text](image.png)